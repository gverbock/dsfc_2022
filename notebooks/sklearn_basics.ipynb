{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_y():\n",
    "    X, y = make_classification(n_samples=500)\n",
    "    X = pd.DataFrame(X)\n",
    "    X.columns = ['var_'+str(i) for i in range(0, X.shape[1])]\n",
    "    y = pd.Series(y)\n",
    "    nan_loc = [(2, 3), (17, 1), (4, 12)]\n",
    "    for loc in nan_loc:\n",
    "        X.iloc[loc] = np.nan\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = make_X_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    steps = [\n",
    "        (\"Impute\", SimpleImputer(strategy=\"mean\")),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        (\"clf\", RandomForestClassifier(max_depth=3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('Impute',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=3, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.943498452012384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "prediction = model.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.944\n",
      "Test set score: 0.856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'clf__max_depth': [3, 5, 7],\n",
    "    'clf__n_estimators': [10, 25, 50, 100],\n",
    "    }\n",
    "\n",
    "grid = RandomizedSearchCV(model, parameters, cv=3, n_iter=10).fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: ' + str(grid.score(X_train, y_train)))\n",
    "print('Test set score: ' + str(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'clf__n_estimators': 25,\n",
       " 'clf__max_depth': 5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('Impute',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=5, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=25, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060088</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030568</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.019596</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053679</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015129</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034575</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.070680</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.019596</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.127981</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.022940</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.033921</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.121209</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015374</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.060088      0.002943         0.004997        0.000287   \n",
       "1       0.030568      0.001245         0.002739        0.000020   \n",
       "2       0.053679      0.000254         0.004827        0.000231   \n",
       "3       0.015129      0.000495         0.001809        0.000024   \n",
       "4       0.034575      0.000472         0.003136        0.000253   \n",
       "5       0.070680      0.001159         0.005779        0.000548   \n",
       "6       0.127981      0.002463         0.009026        0.000610   \n",
       "7       0.033921      0.000300         0.003364        0.000269   \n",
       "8       0.121209      0.001894         0.008477        0.000814   \n",
       "9       0.015374      0.001390         0.001959        0.000310   \n",
       "\n",
       "                                        param_scaler param_clf__n_estimators  \\\n",
       "0      MinMaxScaler(copy=True, feature_range=(0, 1))                      50   \n",
       "1      MinMaxScaler(copy=True, feature_range=(0, 1))                      25   \n",
       "2      MinMaxScaler(copy=True, feature_range=(0, 1))                      50   \n",
       "3      MinMaxScaler(copy=True, feature_range=(0, 1))                      10   \n",
       "4      MinMaxScaler(copy=True, feature_range=(0, 1))                      25   \n",
       "5  StandardScaler(copy=True, with_mean=True, with...                      50   \n",
       "6  StandardScaler(copy=True, with_mean=True, with...                     100   \n",
       "7  StandardScaler(copy=True, with_mean=True, with...                      25   \n",
       "8      MinMaxScaler(copy=True, feature_range=(0, 1))                     100   \n",
       "9  StandardScaler(copy=True, with_mean=True, with...                      10   \n",
       "\n",
       "  param_clf__max_depth                                             params  \\\n",
       "0                    5  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "1                    7  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "2                    3  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "3                    7  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "4                    5  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "5                    7  {'scaler': StandardScaler(copy=True, with_mean...   \n",
       "6                    3  {'scaler': StandardScaler(copy=True, with_mean...   \n",
       "7                    3  {'scaler': StandardScaler(copy=True, with_mean...   \n",
       "8                    7  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "9                    7  {'scaler': StandardScaler(copy=True, with_mean...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0              0.856              0.872              0.904         0.877333   \n",
       "1              0.856              0.880              0.904         0.880000   \n",
       "2              0.864              0.872              0.904         0.880000   \n",
       "3              0.872              0.872              0.888         0.877333   \n",
       "4              0.872              0.872              0.904         0.882667   \n",
       "5              0.856              0.880              0.904         0.880000   \n",
       "6              0.848              0.880              0.904         0.877333   \n",
       "7              0.864              0.872              0.904         0.880000   \n",
       "8              0.872              0.872              0.904         0.882667   \n",
       "9              0.872              0.864              0.880         0.872000   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.019956                7  \n",
       "1        0.019596                3  \n",
       "2        0.017282                3  \n",
       "3        0.007542                7  \n",
       "4        0.015085                1  \n",
       "5        0.019596                3  \n",
       "6        0.022940                7  \n",
       "7        0.017282                3  \n",
       "8        0.015085                1  \n",
       "9        0.006532               10  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
