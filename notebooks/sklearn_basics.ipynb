{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash Course on Sklearn pipelines\n",
    "\n",
    "[Sklearn pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) allow to `stack the different steps of the modelling pipeline` (data transformation, hyper-parameter tuning and model estimation) into a single object. \n",
    "The pipeline is fitted on the training data and can be used to transform new data and estimate the model on it.\n",
    "\n",
    "Each element of the pipeline must have a `fit method`. This method defines the action to perform (for example remove features with missing values).\n",
    "\n",
    "The two main families of pipeline components are:\n",
    "\n",
    "- Transformers: Define how to process data (imputation, outliers, ...).\n",
    "- Estimators: Fit a model and compute predictions (classifier, grid search engine, ...).\n",
    "\n",
    "\n",
    "Pipelines are easy to use and ensure that the same treatment is applied to all data sets. There are many standard functionalities (we will show some of them) and it is also easy to create customized function (classes) to taylor your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ste-up\n",
    "\n",
    "Create a data set to play with and load libraries\n",
    "\n",
    "- For the current notebook we use a small dataset that we artificially create using make classification. \n",
    "  - We use 500 observations.\n",
    "  - We use the default values for the number of relevant, redundants, .... features\n",
    "- We also already load the Pipeline class from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make our own data creating function so that we can directly play with dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_X_y():\n",
    "    X, y = make_classification(n_samples=500)\n",
    "    X = pd.DataFrame(X)\n",
    "    X.columns = ['var_'+str(i) for i in range(0, X.shape[1])]\n",
    "    y = pd.Series(y)\n",
    "    nan_loc = [(2, 3), (17, 1), (4, 12)]\n",
    "    for loc in nan_loc:\n",
    "        X.iloc[loc] = np.nan\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = make_X_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>-0.070558</td>\n",
       "      <td>-0.003146</td>\n",
       "      <td>-0.392045</td>\n",
       "      <td>-0.665389</td>\n",
       "      <td>-0.778423</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>-0.666926</td>\n",
       "      <td>-1.517769</td>\n",
       "      <td>-0.713532</td>\n",
       "      <td>-1.036467</td>\n",
       "      <td>2.570161</td>\n",
       "      <td>-0.285801</td>\n",
       "      <td>1.563787</td>\n",
       "      <td>0.310235</td>\n",
       "      <td>0.271145</td>\n",
       "      <td>-0.677554</td>\n",
       "      <td>-1.616693</td>\n",
       "      <td>-0.391866</td>\n",
       "      <td>1.035647</td>\n",
       "      <td>0.966569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1.788208</td>\n",
       "      <td>1.376253</td>\n",
       "      <td>0.181644</td>\n",
       "      <td>-1.186774</td>\n",
       "      <td>0.091714</td>\n",
       "      <td>0.453242</td>\n",
       "      <td>-1.443753</td>\n",
       "      <td>1.138081</td>\n",
       "      <td>-0.557411</td>\n",
       "      <td>0.032735</td>\n",
       "      <td>0.382635</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>-0.297153</td>\n",
       "      <td>-1.272223</td>\n",
       "      <td>0.168665</td>\n",
       "      <td>-0.181349</td>\n",
       "      <td>1.229209</td>\n",
       "      <td>0.177103</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>2.037883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.794388</td>\n",
       "      <td>-0.489570</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>-2.403328</td>\n",
       "      <td>-1.134548</td>\n",
       "      <td>0.949206</td>\n",
       "      <td>-2.681073</td>\n",
       "      <td>-0.175683</td>\n",
       "      <td>-0.569914</td>\n",
       "      <td>-0.243658</td>\n",
       "      <td>-0.468765</td>\n",
       "      <td>-0.104364</td>\n",
       "      <td>-0.546232</td>\n",
       "      <td>-0.386275</td>\n",
       "      <td>0.221393</td>\n",
       "      <td>-1.064874</td>\n",
       "      <td>-1.436184</td>\n",
       "      <td>-0.595917</td>\n",
       "      <td>-0.220731</td>\n",
       "      <td>-1.265249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.376922</td>\n",
       "      <td>1.469970</td>\n",
       "      <td>0.795458</td>\n",
       "      <td>0.918363</td>\n",
       "      <td>0.328963</td>\n",
       "      <td>0.597953</td>\n",
       "      <td>0.983485</td>\n",
       "      <td>0.581397</td>\n",
       "      <td>-0.224482</td>\n",
       "      <td>-0.089829</td>\n",
       "      <td>-0.521330</td>\n",
       "      <td>1.501288</td>\n",
       "      <td>-1.996734</td>\n",
       "      <td>0.307053</td>\n",
       "      <td>-1.824602</td>\n",
       "      <td>0.058471</td>\n",
       "      <td>1.212209</td>\n",
       "      <td>-0.906636</td>\n",
       "      <td>-0.044441</td>\n",
       "      <td>-0.299773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "255 -0.070558 -0.003146 -0.392045 -0.665389 -0.778423  0.616162 -0.666926   \n",
       "385  1.788208  1.376253  0.181644 -1.186774  0.091714  0.453242 -1.443753   \n",
       "209  1.794388 -0.489570  0.007432 -2.403328 -1.134548  0.949206 -2.681073   \n",
       "177 -0.376922  1.469970  0.795458  0.918363  0.328963  0.597953  0.983485   \n",
       "\n",
       "        var_7     var_8     var_9    var_10    var_11    var_12    var_13  \\\n",
       "255 -1.517769 -0.713532 -1.036467  2.570161 -0.285801  1.563787  0.310235   \n",
       "385  1.138081 -0.557411  0.032735  0.382635  0.002270 -0.297153 -1.272223   \n",
       "209 -0.175683 -0.569914 -0.243658 -0.468765 -0.104364 -0.546232 -0.386275   \n",
       "177  0.581397 -0.224482 -0.089829 -0.521330  1.501288 -1.996734  0.307053   \n",
       "\n",
       "       var_14    var_15    var_16    var_17    var_18    var_19  \n",
       "255  0.271145 -0.677554 -1.616693 -0.391866  1.035647  0.966569  \n",
       "385  0.168665 -0.181349  1.229209  0.177103  0.193200  2.037883  \n",
       "209  0.221393 -1.064874 -1.436184 -0.595917 -0.220731 -1.265249  \n",
       "177 -1.824602  0.058471  1.212209 -0.906636 -0.044441 -0.299773  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in real case we split the data into a train and a test set. For this we use `train_test_split` with the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full modelling pipeline\n",
    "\n",
    "Let's create our first pipeline that will do the following:\n",
    "\n",
    "- `Impute` the missing values (wait.... the data does not have missing values!).\n",
    "- Scale the features using `MinMaxScaler`.\n",
    "- Estimate a `Random Forest Classifier`.\n",
    "\n",
    "Let's load the required functionalities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pipeline\n",
    "\n",
    "`A pipeline is defined by a series or steps`. Each step contains a label and an object. The object is mostly a transformer or an estimator.\n",
    "- In the definition of the pipeline the objects are initiated.\n",
    "- If the objects do not have the required method (fit, transform, predict, ...) the pipeline will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    steps = [\n",
    "        (\"Impute\", SimpleImputer(strategy=\"mean\")),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        (\"clf\", RandomForestClassifier(max_depth=3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the pipeline will do the following:\n",
    "- Compute the value for imputation.\n",
    "- Compute the scaling factor after imputation.\n",
    "- Estimate the Random Forest on the imputed and scaled train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('Impute',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=3, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction\n",
    "\n",
    "The pipeline can be used on the test set to compute the model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9487577639751552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "prediction = model.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing a bit further\n",
    "\n",
    "In the pipeline, we can also `include cross-validation`. This allows o.a. to perform model tuning at different level of the pipeline.\n",
    "To illustrate this, use the pipeline defined above and define 3 parameters we want to tune:\n",
    "- The scaler: Standard vs MinMax.\n",
    "- The maximum depth of the random forest.\n",
    "- The number of estimators of the random forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    'clf__max_depth': [3, 5, 7],\n",
    "    'clf__n_estimators': [10, 25, 50, 100],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In  order to optimize the pipeline, we will use randomized grid search with 10 searches in the 3 dimensional space of hyper-parameters.\n",
    "In order to do so, we provide the pipeline as `input` to the grid search object.\n",
    "[RamdomizedSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9333333333333333\n",
      "Test set score: 0.88\n"
     ]
    }
   ],
   "source": [
    "grid = RandomizedSearchCV(model, parameters, cv=3, n_iter=10).fit(X_train, y_train)\n",
    "\n",
    "print('Training set score: ' + str(grid.score(X_train, y_train)))\n",
    "print('Test set score: ' + str(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then see the best combination of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'clf__n_estimators': 50,\n",
       " 'clf__max_depth': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('Impute',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=5, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=50, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, it is useful to look at the full set of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035623</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.874667</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031884</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014619</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123424</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.063445</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016201</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.063577</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>StandardScaler(copy=True, with_mean=True, with...</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>{'scaler': StandardScaler(copy=True, with_mean...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.019596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.060924</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.140336</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>MinMaxScaler(copy=True, feature_range=(0, 1))</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>{'scaler': MinMaxScaler(copy=True, feature_ran...</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.874667</td>\n",
       "      <td>0.022940</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.035623      0.002476         0.003237        0.000355   \n",
       "1       0.013822      0.000349         0.002197        0.000188   \n",
       "2       0.031884      0.001867         0.003018        0.000310   \n",
       "3       0.014619      0.000179         0.001820        0.000035   \n",
       "4       0.123424      0.002033         0.008005        0.000475   \n",
       "5       0.063445      0.001113         0.004626        0.000165   \n",
       "6       0.016201      0.002325         0.002256        0.000337   \n",
       "7       0.063577      0.000964         0.004708        0.000191   \n",
       "8       0.060924      0.003342         0.005016        0.000712   \n",
       "9       0.140336      0.001724         0.009655        0.000287   \n",
       "\n",
       "                                        param_scaler param_clf__n_estimators  \\\n",
       "0  StandardScaler(copy=True, with_mean=True, with...                      25   \n",
       "1      MinMaxScaler(copy=True, feature_range=(0, 1))                      10   \n",
       "2      MinMaxScaler(copy=True, feature_range=(0, 1))                      25   \n",
       "3  StandardScaler(copy=True, with_mean=True, with...                      10   \n",
       "4      MinMaxScaler(copy=True, feature_range=(0, 1))                     100   \n",
       "5      MinMaxScaler(copy=True, feature_range=(0, 1))                      50   \n",
       "6  StandardScaler(copy=True, with_mean=True, with...                      10   \n",
       "7  StandardScaler(copy=True, with_mean=True, with...                      50   \n",
       "8      MinMaxScaler(copy=True, feature_range=(0, 1))                      50   \n",
       "9      MinMaxScaler(copy=True, feature_range=(0, 1))                     100   \n",
       "\n",
       "  param_clf__max_depth                                             params  \\\n",
       "0                    7  {'scaler': StandardScaler(copy=True, with_mean...   \n",
       "1                    3  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "2                    3  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "3                    7  {'scaler': StandardScaler(copy=True, with_mean...   \n",
       "4                    7  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "5                    7  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "6                    3  {'scaler': StandardScaler(copy=True, with_mean...   \n",
       "7                    5  {'scaler': StandardScaler(copy=True, with_mean...   \n",
       "8                    3  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "9                    5  {'scaler': MinMaxScaler(copy=True, feature_ran...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0              0.896              0.872              0.856         0.874667   \n",
       "1              0.904              0.864              0.848         0.872000   \n",
       "2              0.904              0.864              0.848         0.872000   \n",
       "3              0.888              0.864              0.848         0.866667   \n",
       "4              0.896              0.856              0.856         0.869333   \n",
       "5              0.888              0.856              0.856         0.866667   \n",
       "6              0.880              0.880              0.832         0.864000   \n",
       "7              0.904              0.880              0.856         0.880000   \n",
       "8              0.896              0.864              0.856         0.872000   \n",
       "9              0.904              0.848              0.872         0.874667   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.016438                2  \n",
       "1        0.023551                4  \n",
       "2        0.023551                4  \n",
       "3        0.016438                8  \n",
       "4        0.018856                7  \n",
       "5        0.015085                8  \n",
       "6        0.022627               10  \n",
       "7        0.019596                1  \n",
       "8        0.017282                4  \n",
       "9        0.022940                2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make you own transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Remove feature with less than n distinct values.\"\"\"\n",
    "\n",
    "    def __init__(self, min_number_values):\n",
    "        \"\"\"Initiate the class.\"\"\"\n",
    "        self.min_number_values = min_number_values\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Assess the features to filter out.\"\"\"\n",
    "        self.features_to_drop_ = []\n",
    "        \n",
    "        for feature in X.columns:\n",
    "            number_of_distinct_values = X[feature].nunique()\n",
    "            \n",
    "            if number_of_distinct_values < self.min_number_values:\n",
    "                self.features_to_drop_.append(feature)\n",
    "    \n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"Apply the filter.\"\"\"\n",
    "        return df.drop(columns=self.features_to_drop_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constant</th>\n",
       "      <th>numerical</th>\n",
       "      <th>numerical_2</th>\n",
       "      <th>correlated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   constant  numerical  numerical_2  correlated\n",
       "0         1          1            1         1.7\n",
       "1         1          2            2         4.7\n",
       "2         1          2            3         6.6\n",
       "3         1          1            4         7.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame({\n",
    "    \"constant\": [1, 1, 1, 1],\n",
    "    \"numerical\": [1, 2, 2, 1],\n",
    "    \"numerical_2\": [1, 2, 3, 4],\n",
    "    \"correlated\": [1.7, 4.7, 6.6, 7.8]\n",
    "})\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numerical_2</th>\n",
       "      <th>correlated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numerical_2  correlated\n",
       "0            1         1.7\n",
       "1            2         4.7\n",
       "2            3         6.6\n",
       "3            4         7.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = CustomTransformer(3)\n",
    "transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
